# Advanced Video Stabilization System

This repository presents a comprehensive video stabilization system designed to effectively reduce unwanted camera motion in video sequences. It integrates three distinct motion estimation algorithms: Feature-Based, Optical Flow-Based, and Parametric Motion-Based, providing a flexible and robust solution for various stabilization challenges.

## ‚ú® Features

-   **Multiple Algorithms**: Choose between Feature-Based, Optical Flow-Based, and Parametric Motion-Based stabilization.
-   **Customizable Parameters**: Fine-tune parameters like feature detectors, smoothing radius, and border handling.
-   **Command-Line Interface (CLI)**: Easy-to-use interface for quick stabilization.
-   **Comprehensive Demo**: A script to generate a sample shaky video, run all algorithms, and produce comparison videos and detailed metrics.
-   **Quantitative Metrics**: Evaluate stabilization performance with detailed motion reduction statistics.
-   **Professional Documentation**: In-depth technical document explaining algorithms, implementation, and usage.

## üß† Algorithms Explained

### 1. Feature-Based Stabilization

This method detects and tracks salient points (features like ORB, SIFT, SURF) across frames. It's robust to large motions and effective for general camera shake. Motion is estimated by finding a transformation that best aligns these features.

### 2. Optical Flow-Based Stabilization

Utilizes sparse optical flow (e.g., Lucas-Kanade) to track the movement of a selected set of pixels. This approach is highly efficient and particularly effective for subtle jitters and fine-grained motion compensation.

### 3. Parametric Motion-Based Stabilization

Directly estimates a global geometric transformation (Euclidean, Affine, or Homography) that models the overall motion between frames. This method offers precise control and is ideal when the camera motion conforms to a specific mathematical model.

## üöÄ Getting Started

### Prerequisites

Make sure you have Python 3.x and `pip` installed.

### Installation

1.  Clone the repository:
    ```bash
    git clone https://github.com/AlirezaMirrashid/computer-vision.git
    cd motion-estimation/video-stabilization
    ```
2.  Install the required dependencies:
    ```bash
    pip install -r requirements.txt
    ```

### Running the Demo

The `examples/demo.py` script provides a comprehensive demonstration of all three stabilization algorithms. It will:

1.  Generate a sample shaky video.
2.  Run each stabilization algorithm on the sample video.
3.  Produce stabilized videos, side-by-side comparison videos, and detailed metrics for each algorithm in the `demo_output/` directory.

To run the demo:

```bash
python examples/demo.py
```

After running the demo, check the `demo_output/` directory for the generated videos and metrics.

## üì∫ Video Samples

Here are some video samples generated by the demo, showcasing the effectiveness of each stabilization algorithm. These videos are located in the `assets/` directory after running `examples/demo.py`.

### Original Shaky Video

This is the input video with simulated camera shake.

[sample_shaky_video.mp4](assets/sample_shaky_video.gif)


### Side-by-Side Comparisons

Visual comparisons of the original shaky video versus the stabilized output for each algorithm.

-   **Feature-Based Comparison:** [Feature-Based Comparison](assets/comparison_video_feature.gif)
-   **Optical Flow-Based Comparison:** [Optical Flow-Based Comparison](assets/comparison_video_optical_flow.gif)
-   **Parametric Comparison:** [Parametric Comparison](assets/comparison_video_parametric.gif)
![Parametric Stabilized Video](assets/stabilized_video_parametric.gif)
## üìä Performance Metrics

Detailed performance metrics for each algorithm are saved as JSON files in the `assets/` directory. These metrics include processing time, frames per second (FPS), and motion reduction percentages for X and Y axes.

-   [stabilization_metrics_feature.json](assets/stabilization_metrics_feature.json)
-   [stabilization_metrics_optical_flow.json](assets/stabilization_metrics_optical_flow.json)
-   [stabilization_metrics_parametric.json](assets/stabilization_metrics_parametric.json)


## üíª Usage

### Command-Line Interface (CLI)

To run the CLI, execute `video_stabilizer.py` directly:

```bash
python src/video_stabilizer.py \
    --input /path/to/your_shaky_video.mp4 \
    --output /path/to/your_stabilized_video.mp4 \
    --algorithm feature \
    --smoothing 30 \
    --crop 0.1
```

Replace `/path/to/your_shaky_video.mp4` and `/path/to/your_stabilized_video.mp4` with your actual video paths. You can choose `feature`, `optical_flow`, or `parametric` for the `--algorithm` argument.

## üìÑ Documentation

For a deep dive into the theoretical foundations, implementation details, and advanced usage, refer to the comprehensive technical document:

[Technical Document: Advanced Video Stabilization System](docs/technical_document.md)

## ü§ù Contributing

Contributions are welcome! Please feel free to open issues or submit pull requests.

## üìú License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.



